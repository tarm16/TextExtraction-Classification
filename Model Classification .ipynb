{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ef0ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import warnings\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "import gensim.models\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from tensorboard.compat import tf2 as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import initializers, preprocessing\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, plot_roc_curve\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import enchant\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7537737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TextOfImage = np.load('train_embeddings.npy')\n",
    "val_TextOfImage = np.load('val_embeddings.npy')\n",
    "test_TextOfImage = np.load('test_embeddings.npy')\n",
    "train_TextOfImage = pd.DataFrame({'train_TextOfImage': train_TextOfImage})\n",
    "val_TextOfImage = pd.DataFrame({'val_TextOfImage': val_TextOfImage})\n",
    "test_TextOfImage = pd.DataFrame({'test_TextOfImage': test_TextOfImage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7adb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir un seuil de longueur minimale\n",
    "seuil_longueur_minimale = 5\n",
    "\n",
    "# Filtrer les lignes avec une longueur de texte inférieure au seuil\n",
    "train_TextOfImage = train_TextOfImage[train_TextOfImage['train_TextOfImage'].apply(lambda x: len(str(x)) > seuil_longueur_minimale)]\n",
    "val_TextOfImage = val_TextOfImage[val_TextOfImage['val_TextOfImage'].apply(lambda x: len(str(x)) > seuil_longueur_minimale)]\n",
    "test_TextOfImage = test_TextOfImage[test_TextOfImage['test_TextOfImage'].apply(lambda x: len(str(x)) > seuil_longueur_minimale)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a9c7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "from googletrans import Translator\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "english_words = set(words.words())\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e720484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "\n",
    "def detect_and_translate_to_english(text):\n",
    "    try:\n",
    "        # Détection de la langue\n",
    "        detected_lang = detect(text)\n",
    "        \n",
    "        # Traduction en anglais si la langue détectée n'est pas l'anglais\n",
    "        if detected_lang != 'en':\n",
    "            translator = Translator()\n",
    "            translated_text = translator.translate(text, dest='en').text\n",
    "            return translated_text\n",
    "        else:\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        \n",
    "        return text\n",
    "\n",
    "# Appliquer la fonction à chaque élément de la colonne\n",
    "train_TextOfImage['train_TextOfImage'] = train_TextOfImage['train_TextOfImage'].astype(str).apply(detect_and_translate_to_english)\n",
    "val_TextOfImage['val_TextOfImage'] = val_TextOfImage['val_TextOfImage'].astype(str).apply(detect_and_translate_to_english)\n",
    "test_TextOfImage['test_TextOfImage'] = test_TextOfImage['test_TextOfImage'].astype(str).apply(detect_and_translate_to_english)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dccf4b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove numbers and punctuation\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Replace email addresses with the domain name\n",
    "    email_regex = r'\\S+@\\S+'\n",
    "    email_domains = [re.findall(r'@([\\w.-]+)', email)[0] for email in re.findall(email_regex, text)]\n",
    "    for email_domain in email_domains:\n",
    "        text = re.sub(email_regex, email_domain, text)\n",
    "\n",
    "\n",
    "    # Remove stopwords and words that are not in English\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words and word in english_words]\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Data cleaning\n",
    "train_TextOfImage['train_TextOfImage'] = train_TextOfImage['train_TextOfImage'].apply(clean_text)\n",
    "val_TextOfImage['val_TextOfImage'] = val_TextOfImage['val_TextOfImage'].apply(clean_text)\n",
    "test_TextOfImage['test_TextOfImage'] = test_TextOfImage['test_TextOfImage'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe2a85b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [test_TextOfImage]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Supprimer les lignes avec la valeur 'none' dans la colonne 'test_TextOfImage'\n",
    "test_TextOfImage = test_TextOfImage[test_TextOfImage['test_TextOfImage'] != 'none']\n",
    "\n",
    "# Afficher les premières lignes après la suppression\n",
    "print(test_TextOfImage.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le DataFrame train_TextOfImage\n",
    "train_TextOfImage.to_csv('train_TextOfImage.csv', index=False)\n",
    "\n",
    "# Sauvegarder le DataFrame val_TextOfImage\n",
    "val_TextOfImage.to_csv('val_TextOfImage.csv', index=False)\n",
    "\n",
    "# Sauvegarder le DataFrame test_TextOfImage\n",
    "test_TextOfImage.to_csv('test_TextOfImage.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e6ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('EnronDatasetProjectNew.csv')\n",
    "#data = pd.read_csv('bbc-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "416fa4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business' 'politics' 'sport' 'entertainment' 'tech']\n"
     ]
    }
   ],
   "source": [
    "unique_categories = data[\"category\"].unique()\n",
    "print(unique_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b8e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ae6fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6110, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3e4e82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ami corp royal b ami subject wekend either forward ken lay se atached file mar mar ami corp royal b ami subject wekend either forward ken lay se atached file mar mar\n"
     ]
    }
   ],
   "source": [
    "# Sélectionnez un index spécifique ou utilisez un index aléatoire\n",
    "index = 70\n",
    "\n",
    "# Récupérez le texte de l'e-mail à partir de la colonne \"emailclean\"\n",
    "email_text = data['emailclean'][index]\n",
    "\n",
    "# Affichez le texte de l'e-mail\n",
    "print(email_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4750ec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initialiser les outils NLTK et PyEnchant\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a28d69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    \"a/c\": \"à partir de\",\n",
    "    \"adj.\": \"adjectif\",\n",
    "    \"adv.\": \"adverbe\",\n",
    "    \"cf.\": \"confer (voir)\",\n",
    "    \"c.-à-d.\": \"c'est-à-dire\",\n",
    "    \"etc.\": \"et cetera (et ainsi de suite)\",\n",
    "    \"ex.\": \"exemple\",\n",
    "    \"i.e.\": \"id est (c'est-à-dire)\",\n",
    "    \"journ.\": \"journal\",\n",
    "    \"jr\": \"jour\",\n",
    "    \"l.c.\": \"lettre capitale\",\n",
    "    \"lit.\": \"littéralement\",\n",
    "    \"loc. cit.\": \"loco citato (au même endroit)\",\n",
    "    \"m.\": \"masculin\",\n",
    "    \"masc.\": \"masculin\",\n",
    "    \"min.\": \"minute\",\n",
    "    \"mois.\": \"mois\",\n",
    "    \"n.\": \"nom\",\n",
    "    \"n.d.a.\": \"note de l'auteur\",\n",
    "    \"n.d.l.r.\": \"note de la rédaction\",\n",
    "    \"n.m.\": \"nom masculin\",\n",
    "    \"n.f.\": \"nom féminin\",\n",
    "    \"p.\": \"page\",\n",
    "    \"pl.\": \"pluriel\",\n",
    "    \"s.d.\": \"sans date\",\n",
    "    \"s.n.\": \"sans nom (de l'éditeur)\",\n",
    "    \"s.v.p.\": \"s'il vous plaît\",\n",
    "    \"sig.\": \"signature\",\n",
    "    \"sing.\": \"singulier\",\n",
    "    \"sq.\": \"suivant (paragraphe)\",\n",
    "    \"ss.\": \"suivants (paragraphes)\",\n",
    "    \"s.v.\": \"sub verbo (sous le mot)\",\n",
    "    \"tél.\": \"téléphone\",\n",
    "    \"vol.\": \"volume\",\n",
    "    \"vs\": \"versus (contre)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b0cdffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'URL',text)\n",
    "\n",
    "\n",
    "# Remove HTML beacon\n",
    "def remove_HTML(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "# Remove non printable characters\n",
    "def remove_not_ASCII(text):\n",
    "    text = ''.join([word for word in text if word in string.printable])\n",
    "    return text\n",
    "\n",
    "# Change an abbreviation by its true meaning\n",
    "def word_abbrev(word):\n",
    "    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word\n",
    "\n",
    "# Replace all abbreviations\n",
    "def replace_abbrev(text):\n",
    "    string = \"\"\n",
    "    for word in text.split():\n",
    "        string += word_abbrev(word) + \" \"        \n",
    "    return string\n",
    "\n",
    "# Remove @ and mention, replace by USER\n",
    "def remove_mention(text):\n",
    "    at=re.compile(r'@\\S+')\n",
    "    return at.sub(r'USER',text)\n",
    "                     \n",
    "\n",
    "# Remove numbers, replace it by NUMBER\n",
    "def remove_number(text):\n",
    "    num = re.compile(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
    "    return num.sub(r'NUMBER', text)\n",
    "\n",
    "\n",
    "\n",
    "# Replace some others smileys with SADFACE\n",
    "def transcription_sad(text):\n",
    "    eyes = \"[8:=;]\"\n",
    "    nose = \"['`\\-]\"\n",
    "    smiley = re.compile(r'[8:=;][\\'\\-]?[(\\\\/]')\n",
    "    return smiley.sub(r'SADFACE', text)\n",
    "\n",
    "\n",
    "# Replace some smileys with SMILE\n",
    "def transcription_smile(text):\n",
    "    eyes = \"[8:=;]\"\n",
    "    nose = \"['`\\-]\"\n",
    "    smiley = re.compile(r'[8:=;][\\'\\-]?[)dDp]')\n",
    "    #smiley = re.compile(r'#{eyes}#{nose}[)d]+|[)d]+#{nose}#{eyes}/i')\n",
    "    return smiley.sub(r'SMILE', text)\n",
    "\n",
    "\n",
    "# Replace <3 with HEART\n",
    "def transcription_heart(text):\n",
    "    heart = re.compile(r'<3')\n",
    "    return heart.sub(r'HEART', text)\n",
    "\n",
    "\n",
    "# Factorize elongated words, add ELONG\n",
    "def remove_elongated_words(text):\n",
    "    rep = re.compile(r'\\b(\\S*?)([a-z])\\2{2,}\\b')\n",
    "    return rep.sub(r'\\1\\2 ELONG', text)\n",
    "\n",
    "\n",
    "# Factorize repeated punctuation, add REPEAT\n",
    "def remove_repeat_punct(text):\n",
    "    rep = re.compile(r'([!?.]){2,}')\n",
    "    return rep.sub(r'\\1 REPEAT', text)\n",
    "\n",
    "\n",
    "\n",
    "# Remove all punctuations\n",
    "def remove_all_punct(text):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "\n",
    "# Remove punctuations\n",
    "def remove_punct(text):\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" \n",
    "    for p in punctuations:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "\n",
    "    text = text.replace('...', ' ... ')\n",
    "    if '...' not in text:\n",
    "        text = text.replace('..', ' ... ')   \n",
    "    return text\n",
    "\n",
    "\n",
    "# Remove all english stopwords\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words(\"english\")])\n",
    "    return text\n",
    "\n",
    "def stemming(text):\n",
    "    ps = PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "def lemmatization(text):\n",
    "    lm= WordNetLemmatizer()\n",
    "    text = ' '.join([lm.lemmatize(word, pos='v') for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "84e3b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # Remove non text\n",
    "    text = remove_URL(text)\n",
    "    text = remove_HTML(text)\n",
    "    text = remove_not_ASCII(text)\n",
    "    \n",
    "    # Lower text, replace abbreviations\n",
    "    text = replace_abbrev(text)  \n",
    "    text = remove_mention(text)\n",
    "    text = remove_number(text)\n",
    "    \n",
    "    # Remove  smileys\n",
    "\n",
    "    text = transcription_sad(text)\n",
    "    text = transcription_smile(text)\n",
    "    text = transcription_heart(text)\n",
    "    \n",
    "    # Remove repeated puntuations / words\n",
    "    text = remove_elongated_words(text)\n",
    "    text = remove_repeat_punct(text)\n",
    "\n",
    "    text = remove_all_punct(text)\n",
    "    text = remove_punct(text)\n",
    "    text = lemmatization(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b84c102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emailclean'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6f83058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"C:/Users/PC/OneDrive - Université du Québec en Outaouais/Documents/categorization/savedmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "10e415a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data[\"emailclean\"].apply(lambda x: x.lower()).tolist()\n",
    "# generating training data matrix\n",
    "embed_matrix = []\n",
    "for sent in sentences:\n",
    "    embed_matrix.append(np.array(embed([sent])[0]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "93d70b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming catagories label to \n",
    "labels = data['category'].astype(str)\n",
    "\n",
    "lb = LabelBinarizer().fit(list(set(labels.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "999ea7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up train data and labels (processed)\n",
    "X, Y = np.array(embed_matrix), lb.transform(data['category'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9263c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,stratify=Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a26a4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Model Architecture\n",
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.Input(shape=512))\n",
    "ann.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dropout(0.5))\n",
    "ann.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dropout(0.5))\n",
    "ann.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dropout(0.5))\n",
    "ann.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dropout(0.5))\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=5, activation='softmax'))\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "ann.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy']) \n",
    "\n",
    "# Set up early stopping callback function\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "19955160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 6s 25ms/step - loss: 1.4889 - categorical_accuracy: 0.3382 - val_loss: 1.2532 - val_categorical_accuracy: 0.5026\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 1.2213 - categorical_accuracy: 0.5039 - val_loss: 1.0896 - val_categorical_accuracy: 0.5436\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 1.0857 - categorical_accuracy: 0.5505 - val_loss: 1.0268 - val_categorical_accuracy: 0.5699\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 1.0124 - categorical_accuracy: 0.5766 - val_loss: 0.9390 - val_categorical_accuracy: 0.6093\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.9558 - categorical_accuracy: 0.6074 - val_loss: 0.9539 - val_categorical_accuracy: 0.6157\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 0.8941 - categorical_accuracy: 0.6284 - val_loss: 0.9331 - val_categorical_accuracy: 0.6125\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.8513 - categorical_accuracy: 0.6413 - val_loss: 0.9315 - val_categorical_accuracy: 0.6205\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.8174 - categorical_accuracy: 0.6584 - val_loss: 0.9903 - val_categorical_accuracy: 0.6205\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 0.8030 - categorical_accuracy: 0.6596 - val_loss: 0.8953 - val_categorical_accuracy: 0.6197\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 0.7696 - categorical_accuracy: 0.6769 - val_loss: 0.9280 - val_categorical_accuracy: 0.6288\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = ann.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "08512f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 7ms/step\n",
      "Confusion Matrix:\n",
      " [[151   0   1   0   1]\n",
      " [  0 116   0   0   0]\n",
      " [  1   0 120   3   1]\n",
      " [  0   0   0 154   0]\n",
      " [  1   0   0   0 119]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       1.00      1.00      1.00       116\n",
      "           2       0.99      0.96      0.98       125\n",
      "           3       0.98      1.00      0.99       154\n",
      "           4       0.98      0.99      0.99       120\n",
      "\n",
      "    accuracy                           0.99       668\n",
      "   macro avg       0.99      0.99      0.99       668\n",
      "weighted avg       0.99      0.99      0.99       668\n",
      "\n",
      "Precision: [0.9869281  1.         0.99173554 0.98089172 0.98347107]\n",
      "Recall: [0.9869281  1.         0.96       1.         0.99166667]\n",
      "F1 Score: [0.9869281  1.         0.97560976 0.9903537  0.98755187]\n",
      "Accuracy: 0.9880239520958084\n"
     ]
    }
   ],
   "source": [
    "# Importer les modules nécessaires\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convertir y_test en une liste de labels de classe\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculer la matrice de confusion et afficher le rapport de classification\n",
    "cm = confusion_matrix(y_test_class, y_pred)\n",
    "cr = classification_report(y_test_class, y_pred)\n",
    "\n",
    "# Calculer la précision, le rappel et le score F1 pour chaque classe\n",
    "precision = precision_score(y_test_class, y_pred, average=None)\n",
    "recall = recall_score(y_test_class, y_pred, average=None)\n",
    "f1 = f1_score(y_test_class, y_pred, average=None)\n",
    "\n",
    "# Calculer l'exactitude\n",
    "accuracy = accuracy_score(y_test_class, y_pred)\n",
    "\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "print('Classification Report:\\n', cr)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "208456c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\"\n",
    "import tensorflow_text as text\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "bert_preprocess = hub.KerasLayer(\"C:/Users/PC/OneDrive - Université du Québec en Outaouais/Documents/categorization/bertprocess\")\n",
    "bert_encoder = hub.KerasLayer(\"C:/Users/PC/OneDrive - Université du Québec en Outaouais/Documents/categorization/EncoderBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ce7bfbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_preprocess(sentences)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a2c2d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = data[data['category'] == 'business']\n",
    "df_politics = data[data['category'] == 'politics']\n",
    "df_enter = data[data['category'] == 'entertainment']\n",
    "df_sport = data[data['category'] == 'sport']\n",
    "df_tech = data[data['category'] == 'tech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6632d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Diviser les données en train et test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(data['emailclean'],data['label'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e92315bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labelss = tf.convert_to_tensor(train_labels, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c7cd3d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (embedding), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'pooler_transform/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'pooler_transform/kernel:0' shape=(768, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'embeddings/layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'embeddings/layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'type_embeddings/embeddings:0' shape=(2, 768) dtype=float32>\n",
      "  <tf.Variable 'position_embedding/embeddings:0' shape=(512, 768) dtype=float32>\n",
      "  <tf.Variable 'word_embeddings/embeddings:0' shape=(30522, 768) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "61/61 [==============================] - 544s 9s/step - loss: 0.6553 - accuracy: 0.6419 - val_loss: 0.5783 - val_accuracy: 0.6867\n",
      "Epoch 2/10\n",
      "61/61 [==============================] - 533s 9s/step - loss: 0.5231 - accuracy: 0.7504 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 3/10\n",
      "61/61 [==============================] - 534s 9s/step - loss: 0.4377 - accuracy: 0.8220 - val_loss: 0.4348 - val_accuracy: 0.8050\n",
      "Epoch 4/10\n",
      "61/61 [==============================] - 535s 9s/step - loss: 0.3972 - accuracy: 0.8402 - val_loss: 0.3890 - val_accuracy: 0.8402\n",
      "Epoch 5/10\n",
      "61/61 [==============================] - 530s 9s/step - loss: 0.3633 - accuracy: 0.8588 - val_loss: 0.3616 - val_accuracy: 0.8651\n",
      "Epoch 6/10\n",
      "61/61 [==============================] - 533s 9s/step - loss: 0.3412 - accuracy: 0.8723 - val_loss: 0.3460 - val_accuracy: 0.8651\n",
      "Epoch 7/10\n",
      "61/61 [==============================] - 531s 9s/step - loss: 0.3436 - accuracy: 0.8682 - val_loss: 0.3518 - val_accuracy: 0.8672\n",
      "Epoch 8/10\n",
      "61/61 [==============================] - 531s 9s/step - loss: 0.3336 - accuracy: 0.8765 - val_loss: 0.3425 - val_accuracy: 0.8714\n",
      "Epoch 9/10\n",
      "61/61 [==============================] - 532s 9s/step - loss: 0.3204 - accuracy: 0.8843 - val_loss: 0.3340 - val_accuracy: 0.8714\n",
      "Epoch 10/10\n",
      "61/61 [==============================] - 531s 9s/step - loss: 0.3318 - accuracy: 0.8786 - val_loss: 0.3335 - val_accuracy: 0.8734\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (embedding), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'pooler_transform/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'pooler_transform/kernel:0' shape=(768, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'embeddings/layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'embeddings/layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'type_embeddings/embeddings:0' shape=(2, 768) dtype=float32>\n",
      "  <tf.Variable 'position_embedding/embeddings:0' shape=(512, 768) dtype=float32>\n",
      "  <tf.Variable 'word_embeddings/embeddings:0' shape=(30522, 768) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55/55 [==============================] - 480s 9s/step - loss: 0.7332 - accuracy: 0.5453 - val_loss: 0.6629 - val_accuracy: 0.5553\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 471s 9s/step - loss: 0.6567 - accuracy: 0.6151 - val_loss: 0.6380 - val_accuracy: 0.6198\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 471s 9s/step - loss: 0.6351 - accuracy: 0.6451 - val_loss: 0.6213 - val_accuracy: 0.6359\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 470s 9s/step - loss: 0.6177 - accuracy: 0.6595 - val_loss: 0.6058 - val_accuracy: 0.6498\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 470s 9s/step - loss: 0.5999 - accuracy: 0.6780 - val_loss: 0.5931 - val_accuracy: 0.6682\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 470s 9s/step - loss: 0.5800 - accuracy: 0.7017 - val_loss: 0.6006 - val_accuracy: 0.6429\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 472s 9s/step - loss: 0.5595 - accuracy: 0.7253 - val_loss: 0.5797 - val_accuracy: 0.6659\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 473s 9s/step - loss: 0.5364 - accuracy: 0.7357 - val_loss: 0.5578 - val_accuracy: 0.6935\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 474s 9s/step - loss: 0.5279 - accuracy: 0.7467 - val_loss: 0.5392 - val_accuracy: 0.7097\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 470s 9s/step - loss: 0.5119 - accuracy: 0.7582 - val_loss: 0.5358 - val_accuracy: 0.7120\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (embedding), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'pooler_transform/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'pooler_transform/kernel:0' shape=(768, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'embeddings/layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'embeddings/layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'type_embeddings/embeddings:0' shape=(2, 768) dtype=float32>\n",
      "  <tf.Variable 'position_embedding/embeddings:0' shape=(512, 768) dtype=float32>\n",
      "  <tf.Variable 'word_embeddings/embeddings:0' shape=(30522, 768) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 446s 11s/step - loss: 0.6236 - accuracy: 0.7030 - val_loss: 0.5212 - val_accuracy: 0.7276\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 434s 11s/step - loss: 0.4914 - accuracy: 0.7689 - val_loss: 0.4636 - val_accuracy: 0.7564\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 435s 11s/step - loss: 0.4451 - accuracy: 0.7986 - val_loss: 0.4121 - val_accuracy: 0.8173\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 437s 11s/step - loss: 0.4053 - accuracy: 0.8194 - val_loss: 0.3795 - val_accuracy: 0.8333\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 434s 11s/step - loss: 0.3729 - accuracy: 0.8395 - val_loss: 0.3512 - val_accuracy: 0.8429\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 432s 11s/step - loss: 0.3488 - accuracy: 0.8523 - val_loss: 0.3251 - val_accuracy: 0.8718\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 444s 11s/step - loss: 0.3247 - accuracy: 0.8620 - val_loss: 0.3087 - val_accuracy: 0.8814\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 436s 11s/step - loss: 0.3090 - accuracy: 0.8708 - val_loss: 0.2945 - val_accuracy: 0.8878\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 437s 11s/step - loss: 0.2890 - accuracy: 0.8844 - val_loss: 0.2859 - val_accuracy: 0.8878\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 430s 11s/step - loss: 0.2917 - accuracy: 0.8788 - val_loss: 0.2825 - val_accuracy: 0.8846\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (embedding), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'pooler_transform/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'pooler_transform/kernel:0' shape=(768, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'embeddings/layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'embeddings/layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'type_embeddings/embeddings:0' shape=(2, 768) dtype=float32>\n",
      "  <tf.Variable 'position_embedding/embeddings:0' shape=(512, 768) dtype=float32>\n",
      "  <tf.Variable 'word_embeddings/embeddings:0' shape=(30522, 768) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - 366s 11s/step - loss: 0.7277 - accuracy: 0.5602 - val_loss: 0.6588 - val_accuracy: 0.5955\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 360s 11s/step - loss: 0.6677 - accuracy: 0.5827 - val_loss: 0.6390 - val_accuracy: 0.6554\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 361s 11s/step - loss: 0.6501 - accuracy: 0.6043 - val_loss: 0.6164 - val_accuracy: 0.7154\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 360s 11s/step - loss: 0.6243 - accuracy: 0.6635 - val_loss: 0.6072 - val_accuracy: 0.7079\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 357s 11s/step - loss: 0.6095 - accuracy: 0.6795 - val_loss: 0.5978 - val_accuracy: 0.7116\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 359s 11s/step - loss: 0.5982 - accuracy: 0.6964 - val_loss: 0.6002 - val_accuracy: 0.7041\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 359s 11s/step - loss: 0.5802 - accuracy: 0.7152 - val_loss: 0.5841 - val_accuracy: 0.7004\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 361s 11s/step - loss: 0.5779 - accuracy: 0.7171 - val_loss: 0.5751 - val_accuracy: 0.7154\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 358s 11s/step - loss: 0.5661 - accuracy: 0.7331 - val_loss: 0.5781 - val_accuracy: 0.7154\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 359s 11s/step - loss: 0.5607 - accuracy: 0.7209 - val_loss: 0.5858 - val_accuracy: 0.6891\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (embedding), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'pooler_transform/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'pooler_transform/kernel:0' shape=(768, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_11/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_10/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_9/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_8/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_7/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_6/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_5/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_4/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_3/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_2/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_1/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/output/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/intermediate/bias:0' shape=(3072,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/intermediate/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention_layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention_layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/attention_output/bias:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/attention_output/kernel:0' shape=(12, 64, 768) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/value/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/value/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/key/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/key/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/query/bias:0' shape=(12, 64) dtype=float32>\n",
      "  <tf.Variable 'transformer/layer_0/self_attention/query/kernel:0' shape=(768, 12, 64) dtype=float32>\n",
      "  <tf.Variable 'embeddings/layer_norm/beta:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'embeddings/layer_norm/gamma:0' shape=(768,) dtype=float32>\n",
      "  <tf.Variable 'type_embeddings/embeddings:0' shape=(2, 768) dtype=float32>\n",
      "  <tf.Variable 'position_embedding/embeddings:0' shape=(512, 768) dtype=float32>\n",
      "  <tf.Variable 'word_embeddings/embeddings:0' shape=(30522, 768) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 246s 11s/step - loss: 0.6560 - accuracy: 0.6708 - val_loss: 0.5781 - val_accuracy: 0.6961\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 243s 11s/step - loss: 0.5413 - accuracy: 0.7248 - val_loss: 0.5478 - val_accuracy: 0.7182\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 242s 11s/step - loss: 0.5203 - accuracy: 0.7455 - val_loss: 0.6362 - val_accuracy: 0.6961\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 243s 11s/step - loss: 0.4897 - accuracy: 0.7552 - val_loss: 0.5724 - val_accuracy: 0.7017\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 244s 11s/step - loss: 0.4631 - accuracy: 0.7746 - val_loss: 0.5401 - val_accuracy: 0.7072\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 249s 11s/step - loss: 0.4514 - accuracy: 0.7828 - val_loss: 0.5710 - val_accuracy: 0.7127\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 239s 10s/step - loss: 0.4235 - accuracy: 0.8064 - val_loss: 0.4938 - val_accuracy: 0.7182\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 243s 11s/step - loss: 0.3999 - accuracy: 0.8285 - val_loss: 0.4904 - val_accuracy: 0.7403\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 244s 11s/step - loss: 0.3866 - accuracy: 0.8313 - val_loss: 0.4713 - val_accuracy: 0.7569\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 243s 11s/step - loss: 0.3777 - accuracy: 0.8396 - val_loss: 0.4578 - val_accuracy: 0.7680\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle de classification\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Créer des modèles de classification de spam pour chaque catégorie\n",
    "\n",
    "spam_models = {}\n",
    "\n",
    "for categorie in ['business', 'politics', 'tech', 'sport', 'entertainment']:\n",
    "\n",
    "    # Sélectionner les données pour cette catégorie\n",
    "\n",
    "    df_categorie = data[data['category'] == categorie]\n",
    "\n",
    "    train_texts_categorie = df_categorie['emailclean']\n",
    "\n",
    "    train_labels_categorie = df_categorie['label']\n",
    "\n",
    "    # Diviser les données en train et validation\n",
    "\n",
    "    train_texts_categorie, val_texts_categorie, train_labels_categorie, val_labels_categorie = train_test_split(train_texts_categorie, train_labels_categorie, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convertir les labels en tenseurs\n",
    "\n",
    "    train_labelss_categorie = tf.convert_to_tensor(train_labels_categorie, dtype=tf.float32)\n",
    "\n",
    "    val_labelss_categorie = tf.convert_to_tensor(val_labels_categorie, dtype=tf.float32)\n",
    "\n",
    "    # Encoder les phrases avec BERT\n",
    "\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "\n",
    "    embedding = tf.keras.layers.Lambda(get_sentence_embeding, name='embedding')(text_input)\n",
    "\n",
    "    dense = Dense(256, activation='relu', name='dense')(embedding)\n",
    "\n",
    "    dropout = Dropout(0.1, name='dropout')(dense)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid', name='output')(dropout)\n",
    "\n",
    "    spam_model = tf.keras.Model(inputs=[text_input], outputs=[output])\n",
    "\n",
    "    # Compilation et entraînement du modèle\n",
    "\n",
    "    spam_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Utilisation de la méthode cache pour mettre en cache les données en mémoire pour accélérer l'entraînement du modèle\n",
    "\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((train_texts_categorie.astype(str), train_labelss_categorie)).cache().batch(32)\n",
    "\n",
    "    val_data = tf.data.Dataset.from_tensor_slices((val_texts_categorie.astype(str), val_labelss_categorie)).cache().batch(32)\n",
    "\n",
    "    history = spam_model.fit(train_data, epochs=10, batch_size=32, validation_data=val_data)\n",
    "\n",
    "    # Enregistrer le modèle pour cette catégorie\n",
    "\n",
    "    spam_models[categorie] = spam_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "060360f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance du modèle de classification 1 : business\n",
      "Perte : 0.2448\n",
      "Précision : 0.9171\n",
      "6/6 [==============================] - 50s 8s/step\n",
      "Matrice de confusion:\n",
      " [[119   4]\n",
      " [ 11  47]]\n",
      "Rapport de classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       123\n",
      "           1       0.92      0.81      0.86        58\n",
      "\n",
      "    accuracy                           0.92       181\n",
      "   macro avg       0.92      0.89      0.90       181\n",
      "weighted avg       0.92      0.92      0.92       181\n",
      "\n",
      "Exactitude: 0.9171270718232044\n",
      "Performance du modèle de classification 2 : politics\n",
      "Perte : 0.4555\n",
      "Précision : 0.8398\n",
      "6/6 [==============================] - 58s 10s/step\n",
      "Matrice de confusion:\n",
      " [[116   7]\n",
      " [ 22  36]]\n",
      "Rapport de classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       123\n",
      "           1       0.84      0.62      0.71        58\n",
      "\n",
      "    accuracy                           0.84       181\n",
      "   macro avg       0.84      0.78      0.80       181\n",
      "weighted avg       0.84      0.84      0.83       181\n",
      "\n",
      "Exactitude: 0.8397790055248618\n",
      "Performance du modèle de classification 3 : tech\n",
      "Perte : 0.4317\n",
      "Précision : 0.8232\n",
      "6/6 [==============================] - 105s 17s/step\n",
      "Matrice de confusion:\n",
      " [[93 30]\n",
      " [ 2 56]]\n",
      "Rapport de classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.85       123\n",
      "           1       0.65      0.97      0.78        58\n",
      "\n",
      "    accuracy                           0.82       181\n",
      "   macro avg       0.82      0.86      0.82       181\n",
      "weighted avg       0.87      0.82      0.83       181\n",
      "\n",
      "Exactitude: 0.8232044198895028\n",
      "Performance du modèle de classification 4 : sport\n",
      "Perte : 0.4388\n",
      "Précision : 0.8729\n",
      "6/6 [==============================] - 108s 17s/step\n",
      "Matrice de confusion:\n",
      " [[114   9]\n",
      " [ 14  44]]\n",
      "Rapport de classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       123\n",
      "           1       0.83      0.76      0.79        58\n",
      "\n",
      "    accuracy                           0.87       181\n",
      "   macro avg       0.86      0.84      0.85       181\n",
      "weighted avg       0.87      0.87      0.87       181\n",
      "\n",
      "Exactitude: 0.8729281767955801\n",
      "Performance du modèle de classification 5 : entertainment\n",
      "Perte : 0.4578\n",
      "Précision : 0.7680\n",
      "6/6 [==============================] - 106s 17s/step\n",
      "Matrice de confusion:\n",
      " [[123   0]\n",
      " [ 42  16]]\n",
      "Rapport de classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.85       123\n",
      "           1       1.00      0.28      0.43        58\n",
      "\n",
      "    accuracy                           0.77       181\n",
      "   macro avg       0.87      0.64      0.64       181\n",
      "weighted avg       0.83      0.77      0.72       181\n",
      "\n",
      "Exactitude: 0.7679558011049724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Évaluation des performances des modèles sur les données de test\n",
    "\n",
    "for i, (categorie, model) in enumerate(spam_models.items()):\n",
    "\n",
    "    print(f\"Performance du modèle de classification {i+1} : {categorie}\")\n",
    "\n",
    "    val_loss, val_accuracy = model.evaluate(val_texts_categorie, val_labels_categorie, verbose=0)\n",
    "\n",
    "    print(f\"Perte : {val_loss:.4f}\")\n",
    "\n",
    "    print(f\"Précision : {val_accuracy:.4f}\")\n",
    "\n",
    "    # Faire des prédictions sur les données de validation\n",
    "    y_val_true = val_labelss_categorie.numpy().astype(int)\n",
    "    y_val_pred = np.round(model.predict(val_data)).astype(int)\n",
    "\n",
    "    # Calculer la matrice de confusion et le rapport de classification\n",
    "    cm = confusion_matrix(y_val_true, y_val_pred)\n",
    "    cr = classification_report(y_val_true, y_val_pred)\n",
    "\n",
    "    # Calculer l'exactitude\n",
    "    acc = accuracy_score(y_val_true, y_val_pred)\n",
    "\n",
    "    # Afficher les résultats\n",
    "    print('Matrice de confusion:\\n', cm)\n",
    "    print('Rapport de classification:\\n', cr)\n",
    "    print('Exactitude:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "for history_dict in list_of_histories:\n",
    "    acc = history_dict['accuracy']\n",
    "    val_acc = history_dict['val_accuracy']\n",
    "    loss = history_dict['loss']\n",
    "    val_loss = history_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    # r is for \"solid red line\"\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    # b is for \"solid blue line\"\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    # plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "# r is for \"solid red line\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3053302",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew = pd.read_csv(\"bbc-text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80791e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew['email']=dfnew['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "805fc515",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew=dfnew[\"email\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc2b6905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worldcom boss  left books alone  former worldcom boss bernie ebbers  who is accused of overseeing an $11bn (£5.8bn) fraud  never made accounting decisions  a witness has told jurors.  david myers made the comments under questioning by defence lawyers who have been arguing that mr ebbers was not responsible for worldcom s problems. the phone company collapsed in 2002 and prosecutors claim that losses were hidden to protect the firm s shares. mr myers has already pleaded guilty to fraud and is assisting prosecutors.  on monday  defence lawyer reid weingarten tried to distance his client from the allegations. during cross examination  he asked mr myers if he ever knew mr ebbers  make an accounting decision  .  not that i am aware of   mr myers replied.  did you ever know mr ebbers to make an accounting entry into worldcom books   mr weingarten pressed.  no   replied the witness. mr myers has admitted that he ordered false accounting entries at the request of former worldcom chief financial officer scott sullivan. defence lawyers have been trying to paint mr sullivan  who has admitted fraud and will testify later in the trial  as the mastermind behind worldcom s accounting house of cards.  mr ebbers  team  meanwhile  are looking to portray him as an affable boss  who by his own admission is more pe graduate than economist. whatever his abilities  mr ebbers transformed worldcom from a relative unknown into a $160bn telecoms giant and investor darling of the late 1990s. worldcom s problems mounted  however  as competition increased and the telecoms boom petered out. when the firm finally collapsed  shareholders lost about $180bn and 20 000 workers lost their jobs. mr ebbers  trial is expected to last two months and if found guilty the former ceo faces a substantial jail sentence. he has firmly declared his innocence.\n"
     ]
    }
   ],
   "source": [
    "print(Xnew[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8aad10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Znew=dfnew['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5e65b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5fed3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = np.array([Xnew[1]])\n",
    "df10= pd.DataFrame(ar, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "853f5aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  worldcom boss  left books alone  former worldc...\n"
     ]
    }
   ],
   "source": [
    "print(df10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15fde398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 300ms/step\n"
     ]
    }
   ],
   "source": [
    "y_predicted_bus = modelbusiness.predict(df10) \n",
    "y_predicted_bus = y_predicted_bus.flatten() \n",
    "#spam.append(np.where(y_predicted_bus > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b44449e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Znew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de61c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='email')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "583fc2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 103s 6s/step\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_predicted_bus = modelbusiness.predict(df6['text']) \n",
    "y_predicted_bus = y_predicted_bus.flatten() \n",
    "print(np.where(y_predicted_bus > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1a82af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 483ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 483ms/step\n",
      "1/1 [==============================] - 0s 454ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 1s 551ms/step\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n"
     ]
    }
   ],
   "source": [
    "spam = []\n",
    "\n",
    "for i in range(len(Xnew)): \n",
    "    if Znew[i]=='business' : \n",
    "        ar = np.array([Xnew[i]])\n",
    "        df10= pd.DataFrame(ar, columns=['text'])     \n",
    "        y_predicted_bus = modelbusiness.predict(df10) \n",
    "        y_predicted_bus = y_predicted_bus.flatten() \n",
    "        spam.append(np.where(y_predicted_bus > 0.5, 1, 0)) \n",
    "    elif Znew[i]=='tech' :\n",
    "        ar = np.array([Xnew[i]])\n",
    "        df10= pd.DataFrame(ar, columns=['text'])\n",
    "        y_predicted_tech = modelTech.predict(df10) \n",
    "        y_predicted_tech = y_predicted_tech.flatten() \n",
    "        spam.append(np.where(y_predicted_tech > 0.5, 1, 0)) \n",
    "    elif Znew[i]=='entertainement': \n",
    "        ar = np.array([Xnew[i]])\n",
    "        df10= pd.DataFrame(ar, columns=['text'])\n",
    "        y_predicted_Entert = modelEntertainment.predict(df10) \n",
    "        y_predicted_Entert = y_predicted_Entert.flatten() \n",
    "        spam.append(np.where(y_predicted_Entert > 0.5, 1, 0)) \n",
    "    elif Znew[i]=='sport' : \n",
    "        ar = np.array([Xnew[i]])\n",
    "        df10= pd.DataFrame(ar, columns=['text'])\n",
    "        y_predicted_spo = modelsport.predict(df10) \n",
    "        y_predicted_spo = y_predicted_spo.flatten() \n",
    "        spam.append(np.where(y_predicted_spo > 0.5, 1, 0)) \n",
    "    else : \n",
    "        ar = np.array([Xnew[i]])\n",
    "        df10= pd.DataFrame(ar, columns=['text'])\n",
    "        y_predicted_polit = modelpolitics.predict(df10) \n",
    "        y_predicted_polit= y_predicted_polit.flatten() \n",
    "        spam.append(np.where(y_predicted_polit > 0.5, 1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "57054e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew['spam']=pd.DataFrame(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2a676a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "R=dfnew['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3c363260",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_df_emails = dfnew.to_csv('New_df_emails.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e439ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
